Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Policy/Curiosity Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Policy/Curiosity Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Losses/Curiosity Forward Loss,Losses/Curiosity Inverse Loss,Is Training
1520000,0.71653146,336.8125,-4.1474295,0.3255349,-29.467859636235517,-29.467859636235517,0.08715001004748046,1.3995078,0.02351063,0.0027723317,0.1767846,0.638434,1.0
1540000,1.184682,300.7164179104478,-5.877762,0.27880824,-29.43347058809404,-29.43347058809404,0.9161868745794715,1.4422827,0.030468062,0.0027700227,0.1373066,1.0695947,1.0
1560000,0.7150526,375.7358490566038,-2.3942924,0.33639285,-14.02685871488362,-14.02685871488362,1.413188193485422,0.63436735,0.030191412,0.002766934,0.16216385,0.67481697,1.0
1580000,0.98055965,429.9555555555556,-3.2460678,0.33370993,-31.439978644251823,-31.439978644251823,1.4953475156074596,1.0772302,0.024204576,0.0027638348,0.16101785,0.9089892,1.0
